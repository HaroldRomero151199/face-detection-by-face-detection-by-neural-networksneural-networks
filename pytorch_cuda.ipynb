{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e3b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2970fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de PyTorch instalada: 2.10.0.dev20251004+cu130\n",
      "Análisis: ¡Éxito! La versión de PyTorch ahora tiene soporte para CUDA.\n",
      "Resultado final de torch.cuda.is_available(): True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Versión de PyTorch instalada: {torch.__version__}\")\n",
    "if \"+cu\" in torch.__version__:\n",
    "    print(\"Análisis: ¡Éxito! La versión de PyTorch ahora tiene soporte para CUDA.\")\n",
    "else:\n",
    "    print(\"Análisis: El problema persiste. Verifique la compatibilidad de versiones.\")\n",
    "\n",
    "print(f\"Resultado final de torch.cuda.is_available(): {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a15d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Prueba de Rendimiento de PyTorch: CPU vs. GPU (CUDA) ---\n",
      "\n",
      "✅ Verificación inicial exitosa: PyTorch detecta un dispositivo CUDA.\n",
      "   Dispositivo detectado: NVIDIA GeForce RTX 3090\n",
      "\n",
      "Se realizarán multiplicaciones de matrices de tamaño: 5000x5000\n",
      "\n",
      "[Iniciando prueba en la CPU...]\n",
      "  -> Tiempo de ejecución en CPU: 6.0088 segundos.\n",
      "\n",
      "[Iniciando prueba en la GPU...]\n",
      "  -> Tiempo de ejecución en GPU: 0.2155 segundos.\n",
      "\n",
      "--- Resultados Finales ---\n",
      "Tiempo en CPU: 6.0088 segundos.\n",
      "Tiempo en GPU: 0.2155 segundos.\n",
      "==============================\n",
      "✅ ¡Éxito! La GPU fue aproximadamente 27.9 veces más rápida que la CPU.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Prueba de Rendimiento de PyTorch: CPU vs. GPU (CUDA) ---\")\n",
    "\n",
    "# --- PASO 1: Verificación Fundamental ---\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"\\n❌ ERROR: PyTorch reporta que CUDA no está disponible.\")\n",
    "    print(\"   Asegúrate de haber seguido los pasos de reinstalación forzada.\")\n",
    "    # Si no hay CUDA, no tiene sentido continuar. Detengo el script.\n",
    "    exit()\n",
    "\n",
    "print(\"\\n✅ Verificación inicial exitosa: PyTorch detecta un dispositivo CUDA.\")\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "print(f\"   Dispositivo detectado: {gpu_name}\")\n",
    "\n",
    "# --- PASO 2: Preparación para la Prueba de Rendimiento ---\n",
    "tamano_matriz = 5000\n",
    "print(f\"\\nSe realizarán multiplicaciones de matrices de tamaño: {tamano_matriz}x{tamano_matriz}\")\n",
    "\n",
    "# Creo dos matrices aleatorias grandes en la CPU.\n",
    "matriz_a_cpu = torch.randn(tamano_matriz, tamano_matriz)\n",
    "matriz_b_cpu = torch.randn(tamano_matriz, tamano_matriz)\n",
    "\n",
    "# --- PASO 3: Prueba de Velocidad en la CPU ---\n",
    "print(\"\\n[Iniciando prueba en la CPU...]\")\n",
    "tiempo_inicio_cpu = time.time()\n",
    "\n",
    "# Realizo la multiplicación de matrices en la CPU.\n",
    "for _ in range(10):\n",
    "    resultado_cpu = torch.matmul(matriz_a_cpu, matriz_b_cpu)\n",
    "\n",
    "# Registro el tiempo justo después de terminar.\n",
    "tiempo_fin_cpu = time.time()\n",
    "duracion_cpu = tiempo_fin_cpu - tiempo_inicio_cpu\n",
    "print(f\"  -> Tiempo de ejecución en CPU: {duracion_cpu:.4f} segundos.\")\n",
    "\n",
    "\n",
    "# --- PASO 4: Prueba de Velocidad en la GPU (CUDA) ---\n",
    "print(\"\\n[Iniciando prueba en la GPU...]\")\n",
    "\n",
    "matriz_a_gpu = matriz_a_cpu.to(\"cuda\")\n",
    "matriz_b_gpu = matriz_b_cpu.to(\"cuda\")\n",
    "\n",
    "# Registro el tiempo de inicio.\n",
    "tiempo_inicio_gpu = time.time()\n",
    "\n",
    "# Realizo exactamente la misma multiplicación, pero ahora con los tensores que están en la GPU.\n",
    "for _ in range(10):\n",
    "    resultado_gpu = torch.matmul(matriz_a_gpu, matriz_b_gpu)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "tiempo_fin_gpu = time.time()\n",
    "duracion_gpu = tiempo_fin_gpu - tiempo_inicio_gpu\n",
    "print(f\"  -> Tiempo de ejecución en GPU: {duracion_gpu:.4f} segundos.\")\n",
    "\n",
    "\n",
    "# --- PASO 5: Conclusión ---\n",
    "print(\"\\n--- Resultados Finales ---\")\n",
    "print(f\"Tiempo en CPU: {duracion_cpu:.4f} segundos.\")\n",
    "print(f\"Tiempo en GPU: {duracion_gpu:.4f} segundos.\")\n",
    "print(\"=\"*30)\n",
    "if duracion_gpu < duracion_cpu:\n",
    "    factor_velocidad = duracion_cpu / duracion_gpu\n",
    "    print(f\"✅ ¡Éxito! La GPU fue aproximadamente {factor_velocidad:.1f} veces más rápida que la CPU.\")\n",
    "else:\n",
    "    print(\"⚠️  Atención: La GPU no fue más rápida. Esto puede ocurrir con matrices muy pequeñas\")\n",
    "    print(\"   o si la GPU es de gama muy baja. Intenta aumentar el 'tamano_matriz'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4343409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
